{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "L8ytb6-HKee0"
      },
      "outputs": [],
      "source": [
        "essay=\"\"\"\n",
        "Global warming, an existential challenge of our era, stems from the accumulation of greenhouse gases in the Earth's atmosphere, predominantly carbon dioxide, methane, and nitrous oxide. These gases trap heat that would otherwise escape into space, leading to a warming effect known as the greenhouse effect. While a certain level of greenhouse gases is natural and necessary to maintain Earth's temperature conducive to life, human activities since the Industrial Revolution have significantly amplified these gases' concentration, primarily through the burning of fossil fuels, deforestation, and industrial processes.\n",
        "\n",
        "The consequences of global warming are multifaceted and far-reaching, impacting ecological systems, human societies, and economies worldwide. One of the most visible effects is the rapid melting of polar ice caps and glaciers. This accelerated ice loss contributes to rising sea levels, threatening low-lying coastal areas and island nations with inundation and increased vulnerability to storm surges and flooding. Coastal erosion is exacerbating, endangering infrastructure and habitats crucial for biodiversity.\n",
        "\n",
        "Moreover, global warming influences weather patterns, leading to more frequent and intense extreme weather events such as hurricanes, heatwaves, droughts, and heavy rainfall. These events not only pose immediate risks to human lives and property but also disrupt agriculture, water supply, and public health systems. For instance, prolonged droughts can lead to crop failures and food shortages, while heatwaves increase the incidence of heat-related illnesses and deaths, particularly among vulnerable populations such as the elderly and outdoor workers.\n",
        "\n",
        "Beyond its direct environmental and health impacts, global warming exacerbates existing social inequalities and economic disparities. Vulnerable communities, including indigenous peoples, minorities, and low-income populations, often bear the brunt of climate change's adverse effects despite contributing minimally to greenhouse gas emissions. They face challenges in adapting to changing conditions due to limited resources, inadequate infrastructure, and less access to information and support services.\n",
        "\n",
        "Economically, industries reliant on natural resources sensitive to climate change, such as agriculture, fisheries, and tourism, are particularly susceptible to disruptions caused by global warming. Losses in these sectors not only affect local economies but also have ripple effects on global supply chains and markets. Moreover, the costs associated with climate-related disasters, including emergency response, infrastructure repair, and loss of productivity, place a significant burden on national budgets and international aid efforts.\n",
        "\n",
        "Scientific consensus attributes the majority of global warming to human activities, particularly the burning of fossil fuels for energy production, transportation, and industrial processes. This has led to an increase in atmospheric carbon dioxide levels from around 280 parts per million (ppm) before the Industrial Revolution to over 415 ppm in recent yearsâ€”a level unprecedented in at least the last 800,000 years.\n",
        "\n",
        "Addressing global warming requires urgent and concerted action at local, national, and international levels. The Paris Agreement, adopted in 2015 by nearly every country in the world, aims to limit global temperature rise well below 2 degrees Celsius above pre-industrial levels, with efforts to limit the increase to 1.5 degrees Celsius. Achieving these goals necessitates rapid and substantial reductions in greenhouse gas emissions, transitioning to renewable energy sources such as solar, wind, and hydroelectric power, and implementing energy-efficient technologies and practices across sectors.\n",
        "\n",
        "In addition to mitigation efforts, adaptation strategies are crucial to minimize the impacts of climate change on vulnerable communities and ecosystems. These strategies include enhancing resilience to extreme weather events, implementing sustainable land use and water management practices, and investing in climate-resilient infrastructure. Moreover, fostering international cooperation and partnerships is essential to mobilize resources, share knowledge and technology, and support developing countries in their climate action efforts.\n",
        "\n",
        "While the challenges posed by global warming are daunting, there is reason for hope. Innovations in clean energy technologies, such as electric vehicles, energy storage systems, and renewable energy sources, offer promising pathways to reduce emissions and transition towards a sustainable, low-carbon economy. Furthermore, grassroots movements, youth activism, and advocacy efforts are driving awareness and political momentum for ambitious climate action.\n",
        "\n",
        "Ultimately, addressing global warming requires a collective commitment to protect the planet's ecosystems, safeguard human health and well-being, and promote equitable and sustainable development for present and future generations. By taking bold and decisive action now, we can mitigate the worst impacts of climate change and create a resilient and prosperous future for all.\n",
        "\n",
        "\n",
        "Global warming, driven primarily by the accumulation of greenhouse gases like carbon dioxide and methane, poses a profound threat to global ecosystems, economies, and human well-being. Beyond melting polar ice caps and rising sea levels that endanger coastal communities, climate change intensifies extreme weather events, exacerbates biodiversity loss, and contributes to ocean acidification, threatening marine life and fisheries. Feedback loops, such as melting permafrost releasing methane, further amplify warming. This crisis also fuels displacement and migration due to environmental degradation, heightening social tensions and straining resources. Globally interconnected impacts include geopolitical instability from climate-induced conflicts over dwindling resources. Ethical considerations regarding fairness and intergenerational justice underscore the urgency of collective action. Education and awareness are pivotal in empowering societies to advocate for sustainable practices and policies. Innovation in clean technologies and renewable energy offers promising solutions, supporting both mitigation efforts and adaptation strategies crucial for building resilience. Addressing global warming demands immediate and concerted efforts to mitigate emissions, adapt to inevitable changes, and foster international cooperation towards a sustainable and equitable future for all.\n",
        "\n",
        "Global warming, driven primarily by the accumulation of greenhouse gases like carbon dioxide and methane, poses a profound threat to global ecosystems, economies, and human well-being. Beyond melting polar ice caps and rising sea levels that endanger coastal communities, climate change intensifies extreme weather events, exacerbates biodiversity loss, and contributes to ocean acidification, threatening marine life and fisheries. Feedback loops, such as melting permafrost releasing methane, further amplify warming. This crisis also fuels displacement and migration due to environmental degradation, heightening social tensions and straining resources. Globally interconnected impacts include geopolitical instability from climate-induced conflicts over dwindling resources. Ethical considerations regarding fairness and intergenerational justice underscore the urgency of collective action. Education and awareness are pivotal in empowering societies to advocate for sustainable practices and policies. Innovation in clean technologies and renewable energy offers promising solutions, supporting both mitigation efforts and adaptation strategies crucial for building resilience. Addressing global warming demands immediate and concerted efforts to mitigate emissions, adapt to inevitable changes, and foster international cooperation towards a sustainable and equitable future for all.\n",
        "\n",
        "The impacts of global warming on biodiversity are severe and accelerating. Species are facing rapid habitat loss and shifts in their ranges as ecosystems struggle to adapt to changing climates. Coral reefs, for instance, suffer from bleaching events due to warmer ocean temperatures, threatening the diverse marine life they support. Terrestrial ecosystems are also under pressure, with vulnerable species such as polar bears and mountain-dwelling mammals facing shrinking habitats. Moreover, the loss of biodiversity reduces the resilience of ecosystems to other environmental stresses, such as pollution and invasive species, further compromising their ability to provide essential services like clean water and air.\n",
        "\n",
        "Socially and economically, vulnerable populations bear the brunt of climate impacts despite contributing the least to greenhouse gas emissions. Low-income communities, indigenous peoples, and marginalized groups often lack resources and infrastructure to cope with extreme weather events and slow-onset climate changes like desertification or sea-level rise. This disparity exacerbates inequalities and can lead to social unrest and conflict over dwindling resources such as water and arable land. Climate refugees are increasingly seeking safety and livelihoods elsewhere, straining humanitarian systems and provoking debates over migration policies and responsibilities.\n",
        "\n",
        "The economic costs of inaction on climate change are substantial. Climate-related disasters, including hurricanes, floods, and wildfires, result in billions of dollars in damages annually, affecting sectors from agriculture to insurance and tourism. Businesses and governments face escalating costs for rebuilding infrastructure, restoring ecosystems, and addressing health impacts from heatwaves and air pollution. Transitioning to a low-carbon economy presents opportunities for job creation and economic growth, particularly in renewable energy sectors, but requires strategic investments and policies to ensure a just transition for workers and communities dependent on fossil fuel industries.\n",
        "\n",
        "Mitigating greenhouse gas emissions requires transformative changes across energy, transportation, industry, agriculture, and land-use sectors. This entails transitioning from fossil fuels to renewable energy sources such as solar, wind, and hydroelectric power, improving energy efficiency in buildings and transportation, and implementing policies to incentivize sustainable practices and technologies. The Paris Agreement provides a framework for global cooperation, setting ambitious targets to limit temperature rise and mobilize financial and technological support for developing countries. However, achieving these goals demands political will, robust implementation mechanisms, and ongoing monitoring and transparency to hold countries accountable for their commitments.\n",
        "\n",
        "Adaptation strategies are equally crucial to minimize the impacts of climate change on vulnerable communities and ecosystems. This includes investing in climate-resilient infrastructure, enhancing early warning systems for extreme weather events, and promoting sustainable land-use and water management practices. Indigenous knowledge and local innovations play a vital role in developing context-specific adaptation strategies that build on community strengths and resilience.\n",
        "\n",
        "Education and public awareness are fundamental in catalyzing climate action at all levels of society. By fostering understanding of climate science, impacts, and solutions, education empowers individuals to make informed choices in their daily lives, advocate for policy change, and participate in collective efforts to reduce emissions and build resilience. Media coverage, public discourse, and cultural initiatives also shape attitudes towards climate change, influencing political agendas and corporate behaviors towards sustainability and environmental stewardship.\n",
        "\n",
        "Innovation in technology and policy is essential to accelerate the transition to a low-carbon economy and enhance climate resilience. Research and development in areas such as carbon capture and storage, sustainable agriculture, and climate-friendly urban planning are critical for achieving long-term climate goals. Public-private partnerships and international collaborations can leverage expertise and resources to scale up innovative solutions and overcome barriers to adoption and implementation.\n",
        "\n",
        "Ethical considerations underpin the urgency of climate action, particularly in addressing historical and current disparities in emissions and vulnerabilities. Principles of justice, equity, and human rights are central to shaping fair and inclusive climate policies that prioritize the needs of marginalized communities and future generations. International climate negotiations must address these ethical dimensions to build trust, solidarity, and shared responsibility in tackling the global challenge of climate change.\n",
        "\n",
        "In conclusion, addressing global warming requires a holistic approach that integrates mitigation, adaptation, equity, and international cooperation. By committing to ambitious climate goals, investing in sustainable development, and empowering communities to adapt and thrive in a changing climate, humanity can forge a path towards a resilient and equitable future. The time for decisive action is now, as the consequences of inaction on climate change are already profound and will continue to escalate without concerted global efforts to mitigate and adapt to this defining challenge of the 21st century.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_9ZEeuuJLD1m"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_9r-1w0PLIX6"
      },
      "outputs": [],
      "source": [
        "tokenizer=Tokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8REiG0ISLUql"
      },
      "outputs": [],
      "source": [
        "tokenizer.fit_on_texts([essay])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTYM82mVLaLi",
        "outputId": "07b3e0f4-098b-49b8-aa8b-b4bc9a418687"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "649"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(tokenizer.word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyuGZIB3LhAD",
        "outputId": "662c920f-5549-481a-9df2-06d5a85fe99f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "input_sequences = []\n",
        "for sentence in essay.split('.'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1,len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[:i+1])\n",
        "  print(input_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-mFea8BmM4q4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39839a3f-53ed-4493-c9db-3ce2d031457a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "max_len = max([len(x) for x in input_sequences])\n",
        "max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2SbYWL1nM_D1"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VK5GrN-xNXH4",
        "outputId": "4f4c6b2a-629b-49b7-8c90-cdecca228aba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 10, 171, 280, ...,   3, 648, 649], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "X = padded_input_sequences[:,:-1]\n",
        "y = padded_input_sequences[:,-1]\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3F5qejtNiyW",
        "outputId": "21f9e274-8c9a-46bc-c002-ffd0690f030a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y,num_classes=650)\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UIzIWPceNoOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a15370b-e8a2-41b7-8d21-630771e8f9e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1725, 40), (1725, 650))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "\n",
        "X.shape,y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "D3_qPtR1PAJM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense,Input, Multiply,Softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dOWewEbBPWL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba77bee6-7bfb-4b82-9d15-0e6f74302d07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 40)]                 0         []                            \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)     (None, 40, 150)              97500     ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)               (None, 150)                  180600    ['embedding_2[0][0]']         \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)     (None, 150, 150)             97500     ['lstm_3[0][0]']              \n",
            "                                                                                                  \n",
            " lstm_4 (LSTM)               (None, 150, 150)             180600    ['embedding_3[0][0]']         \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)       (None, 150, 150)             0         ['lstm_3[0][0]',              \n",
            "                                                                     'lstm_4[0][0]']              \n",
            "                                                                                                  \n",
            " lstm_5 (LSTM)               (None, 150)                  180600    ['multiply_2[0][0]']          \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 650)                  98150     ['lstm_5[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 834950 (3.19 MB)\n",
            "Trainable params: 834950 (3.19 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(650, 150, input_length=40))\n",
        "# model.add(LSTM(150,return_sequences=True))\n",
        "# model.add(LSTM(150,return_sequences=False))\n",
        "# model.add(Dense(650, activation='softmax'))\n",
        "\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(40,))\n",
        "encoder_embedding = Embedding(650, 150, input_length=40)(encoder_inputs)\n",
        "encoder_lstm = LSTM(150, return_sequences=False)(encoder_embedding)\n",
        "\n",
        "# Decoder\n",
        "# decoder_inputs = Input(shape=(40,))\n",
        "decoder_embedding = Embedding(650, 150, input_length=40)(encoder_lstm)\n",
        "decoder_lstm1 = LSTM(150, return_sequences=True)(decoder_embedding)\n",
        "dot= Multiply()([encoder_lstm,decoder_lstm1])\n",
        "dot2= Multiply()([encoder_lstm,dot])\n",
        "decoder_lstm2 = LSTM(150, return_sequences=False)(dot)\n",
        "decoder_dense = Dense(650, activation='softmax')(decoder_lstm2)\n",
        "model=Model(encoder_inputs,decoder_dense)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Jfi4NKj-P1XP"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "nN-kvIr0QCgO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47b63894-e654-4ab4-8a9f-0fb3af71d2d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 2.3120 - accuracy: 0.4435\n",
            "Epoch 2/100\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 2.2041 - accuracy: 0.4522\n",
            "Epoch 3/100\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 2.1115 - accuracy: 0.4696\n",
            "Epoch 4/100\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 2.0184 - accuracy: 0.4962\n",
            "Epoch 5/100\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 1.9959 - accuracy: 0.5038\n",
            "Epoch 6/100\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 1.9147 - accuracy: 0.5246\n",
            "Epoch 7/100\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 1.8798 - accuracy: 0.5328\n",
            "Epoch 8/100\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 1.8801 - accuracy: 0.5386\n",
            "Epoch 9/100\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 1.9479 - accuracy: 0.4933\n",
            "Epoch 10/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.8655 - accuracy: 0.5217\n",
            "Epoch 11/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.8904 - accuracy: 0.5246\n",
            "Epoch 12/100\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 1.8398 - accuracy: 0.5472\n",
            "Epoch 13/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.7300 - accuracy: 0.5774\n",
            "Epoch 14/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.7726 - accuracy: 0.5501\n",
            "Epoch 15/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.6783 - accuracy: 0.5849\n",
            "Epoch 16/100\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 1.6206 - accuracy: 0.5971\n",
            "Epoch 17/100\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 1.6298 - accuracy: 0.6000\n",
            "Epoch 18/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.5315 - accuracy: 0.6290\n",
            "Epoch 19/100\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 1.5237 - accuracy: 0.6296\n",
            "Epoch 20/100\n",
            "54/54 [==============================] - 2s 28ms/step - loss: 1.6776 - accuracy: 0.5768\n",
            "Epoch 21/100\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 1.5828 - accuracy: 0.5994\n",
            "Epoch 22/100\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 1.4832 - accuracy: 0.6301\n",
            "Epoch 23/100\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 1.4248 - accuracy: 0.6493\n",
            "Epoch 24/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.3801 - accuracy: 0.6638\n",
            "Epoch 25/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.3471 - accuracy: 0.6881\n",
            "Epoch 26/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.3430 - accuracy: 0.6783\n",
            "Epoch 27/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.2884 - accuracy: 0.7101\n",
            "Epoch 28/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.3400 - accuracy: 0.6754\n",
            "Epoch 29/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.2716 - accuracy: 0.7067\n",
            "Epoch 30/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.2292 - accuracy: 0.7293\n",
            "Epoch 31/100\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 1.1587 - accuracy: 0.7472\n",
            "Epoch 32/100\n",
            "54/54 [==============================] - 1s 25ms/step - loss: 1.0953 - accuracy: 0.7675\n",
            "Epoch 33/100\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 1.0702 - accuracy: 0.7664\n",
            "Epoch 34/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.0489 - accuracy: 0.7780\n",
            "Epoch 35/100\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 1.0495 - accuracy: 0.7733\n",
            "Epoch 36/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.0259 - accuracy: 0.7814\n",
            "Epoch 37/100\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 1.0730 - accuracy: 0.7594\n",
            "Epoch 38/100\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 1.0109 - accuracy: 0.7849\n",
            "Epoch 39/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 1.2819 - accuracy: 0.6893\n",
            "Epoch 40/100\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 1.0786 - accuracy: 0.7577\n",
            "Epoch 41/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.9766 - accuracy: 0.8006\n",
            "Epoch 42/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.9503 - accuracy: 0.7983\n",
            "Epoch 43/100\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.8989 - accuracy: 0.8209\n",
            "Epoch 44/100\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.8300 - accuracy: 0.8458\n",
            "Epoch 45/100\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.7919 - accuracy: 0.8516\n",
            "Epoch 46/100\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.7792 - accuracy: 0.8574\n",
            "Epoch 47/100\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.7962 - accuracy: 0.8510\n",
            "Epoch 48/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.7807 - accuracy: 0.8614\n",
            "Epoch 49/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.7318 - accuracy: 0.8748\n",
            "Epoch 50/100\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.6924 - accuracy: 0.8725\n",
            "Epoch 51/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.6779 - accuracy: 0.8875\n",
            "Epoch 52/100\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.7635 - accuracy: 0.8586\n",
            "Epoch 53/100\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.6730 - accuracy: 0.8783\n",
            "Epoch 54/100\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.6518 - accuracy: 0.8939\n",
            "Epoch 55/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.6498 - accuracy: 0.8887\n",
            "Epoch 56/100\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.6558 - accuracy: 0.8829\n",
            "Epoch 57/100\n",
            "54/54 [==============================] - 1s 24ms/step - loss: 0.6089 - accuracy: 0.8922\n",
            "Epoch 58/100\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.5787 - accuracy: 0.9096\n",
            "Epoch 59/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5325 - accuracy: 0.9119\n",
            "Epoch 60/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5864 - accuracy: 0.8945\n",
            "Epoch 61/100\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.5148 - accuracy: 0.9148\n",
            "Epoch 62/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4659 - accuracy: 0.9328\n",
            "Epoch 63/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4615 - accuracy: 0.9333\n",
            "Epoch 64/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.5229 - accuracy: 0.9096\n",
            "Epoch 65/100\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.4824 - accuracy: 0.9206\n",
            "Epoch 66/100\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.4427 - accuracy: 0.9264\n",
            "Epoch 67/100\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.4203 - accuracy: 0.9386\n",
            "Epoch 68/100\n",
            "54/54 [==============================] - 1s 19ms/step - loss: 0.4798 - accuracy: 0.9241\n",
            "Epoch 69/100\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.4286 - accuracy: 0.9322\n",
            "Epoch 70/100\n",
            "54/54 [==============================] - 1s 21ms/step - loss: 0.3956 - accuracy: 0.9362\n",
            "Epoch 71/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4009 - accuracy: 0.9403\n",
            "Epoch 72/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4009 - accuracy: 0.9357\n",
            "Epoch 73/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4621 - accuracy: 0.9206\n",
            "Epoch 74/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.4253 - accuracy: 0.9264\n",
            "Epoch 75/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.3838 - accuracy: 0.9426\n",
            "Epoch 76/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.3593 - accuracy: 0.9467\n",
            "Epoch 77/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.3179 - accuracy: 0.9571\n",
            "Epoch 78/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.3544 - accuracy: 0.9449\n",
            "Epoch 79/100\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.3630 - accuracy: 0.9414\n",
            "Epoch 80/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.3499 - accuracy: 0.9414\n",
            "Epoch 81/100\n",
            "54/54 [==============================] - 1s 23ms/step - loss: 0.3075 - accuracy: 0.9548\n",
            "Epoch 82/100\n",
            "54/54 [==============================] - 1s 26ms/step - loss: 0.2780 - accuracy: 0.9612\n",
            "Epoch 83/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.2815 - accuracy: 0.9548\n",
            "Epoch 84/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.2862 - accuracy: 0.9536\n",
            "Epoch 85/100\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.2940 - accuracy: 0.9536\n",
            "Epoch 86/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.3030 - accuracy: 0.9496\n",
            "Epoch 87/100\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2733 - accuracy: 0.9565\n",
            "Epoch 88/100\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.2566 - accuracy: 0.9600\n",
            "Epoch 89/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.2150 - accuracy: 0.9687\n",
            "Epoch 90/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.1985 - accuracy: 0.9710\n",
            "Epoch 91/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.1888 - accuracy: 0.9704\n",
            "Epoch 92/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.1821 - accuracy: 0.9739\n",
            "Epoch 93/100\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.1763 - accuracy: 0.9722\n",
            "Epoch 94/100\n",
            "54/54 [==============================] - 1s 26ms/step - loss: 0.1643 - accuracy: 0.9762\n",
            "Epoch 95/100\n",
            "54/54 [==============================] - 1s 22ms/step - loss: 0.1571 - accuracy: 0.9768\n",
            "Epoch 96/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.1489 - accuracy: 0.9762\n",
            "Epoch 97/100\n",
            "54/54 [==============================] - 1s 18ms/step - loss: 0.1416 - accuracy: 0.9762\n",
            "Epoch 98/100\n",
            "54/54 [==============================] - 1s 20ms/step - loss: 0.1392 - accuracy: 0.9745\n",
            "Epoch 99/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.1394 - accuracy: 0.9745\n",
            "Epoch 100/100\n",
            "54/54 [==============================] - 1s 17ms/step - loss: 0.1360 - accuracy: 0.9791\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b0beadc3130>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "model.fit(X,y,epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "u8f2VuT9QOHL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "236b4eef-1d7a-4226-fea6-4cefbffc4590"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n",
            "we should protect as\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "we should protect as hurricanes\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "we should protect as hurricanes heatwaves\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "we should protect as hurricanes heatwaves droughts\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "we should protect as hurricanes heatwaves droughts and\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "we should protect as hurricanes heatwaves droughts and governments\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "we should protect as hurricanes heatwaves droughts and governments face\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "we should protect as hurricanes heatwaves droughts and governments face escalating\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "we should protect as hurricanes heatwaves droughts and governments face escalating costs\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "we should protect as hurricanes heatwaves droughts and governments face escalating costs for\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "text = \"we should protect\"\n",
        "\n",
        "for i in range(10):\n",
        "  # tokenize\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  # padding\n",
        "  padded_token_text = pad_sequences([token_text], maxlen=40, padding='pre')\n",
        "  # predict\n",
        "  pos = np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index == pos:\n",
        "      text = text + \" \" + word\n",
        "      print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5mWvoxOQwn7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}